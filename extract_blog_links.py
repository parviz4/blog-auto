#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
import json

BLOG_URL = "https://rasta4u.blogfa.com"

def extract_active_blog_links():
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙØ¹Ø§Ù„ ÙˆØ¨Ù„Ø§Ú¯"""
    print("ğŸ” Ø¯Ø±Ø­Ø§Ù„ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ ÙˆØ¨Ù„Ø§Ú¯...\n")
    
    try:
        response = requests.get(BLOG_URL, timeout=10)
        soup = BeautifulSoup(response.content, 'html.parser')
        
        active_links = {}
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ…Ø§Ù… Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ post (Ù…Ù‚Ø§Ù„Ø§Øª)
        print("ğŸ“„ Ù…Ù‚Ø§Ù„Ø§Øª:")
        post_links = []
        for link in soup.find_all('a', href=True):
            url = link['href']
            text = link.get_text(strip=True)
            
            if '/post/' in url and text and len(text) > 3:
                full_url = urljoin(BLOG_URL, url)
                if full_url not in [l['url'] for l in post_links]:
                    post_links.append({
                        'title': text[:100],
                        'url': full_url
                    })
                    print(f"  âœ… {text[:60]}")
        
        active_links['posts'] = post_links
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§
        print(f"\nğŸ“‚ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒâ€ŒÙ‡Ø§:")
        category_links = []
        for link in soup.find_all('a', href=True):
            if '/category/' in link['href']:
                full_url = urljoin(BLOG_URL, link['href'])
                text = link.get_text(strip=True)
                
                if text and len(text) > 2 and full_url not in [l['url'] for l in category_links]:
                    category_links.append({
                        'title': f"Ø¯Ø³ØªÙ‡: {text}",
                        'url': full_url
                    })
                    print(f"  âœ… {text}")
        
        active_links['categories'] = category_links
        
        # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ÙØ§ÛŒÙ„
        with open('active_blog_links.json', 'w', encoding='utf-8') as f:
            json.dump(active_links, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… {len(post_links)} Ù…Ù‚Ø§Ù„Ù‡ + {len(category_links)} Ø¯Ø³ØªÙ‡ = Ú©Ù„ {len(post_links) + len(category_links)} Ù„ÛŒÙ†Ú©")
        print("ğŸ“ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: active_blog_links.json\n")
        
        return active_links
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§: {e}")
        return {}

if __name__ == '__main__':
    extract_active_blog_links()
